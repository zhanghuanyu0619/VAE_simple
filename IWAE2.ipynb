{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T22:48:36.916644Z",
     "start_time": "2023-10-09T22:48:35.445548Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import distributions\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import imageio\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def save_generator_image(image, path):\n",
    "    save_image(image, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import distributions as D\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, latent_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, H)\n",
    "        self.enc_mu = torch.nn.Linear(H, latent_size)\n",
    "        self.enc_log_sigma = torch.nn.Linear(H, latent_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        mu = self.enc_mu(x)\n",
    "        log_sigma = self.enc_log_sigma(x)\n",
    "        sigma = torch.exp(log_sigma)\n",
    "        return torch.distributions.Normal(loc=mu, scale=sigma)\n",
    "\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        mu = torch.tanh(self.linear2(x))\n",
    "        return torch.distributions.Normal(mu, torch.ones_like(mu))\n",
    "\n",
    "class VAE(torch.nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, state):\n",
    "        q_z = self.encoder(state)\n",
    "        z = q_z.rsample()\n",
    "        return self.decoder(z), q_z\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     # Normalize the images to be -0.5, 0.5\n",
    "     transforms.Normalize(0.5, 1)]\n",
    "    )\n",
    "\n",
    "class IWAE(VAE):\n",
    "    def __init__(self, encoder, decoder, k=1, m=1):\n",
    "        super(IWAE, self).__init__(encoder, decoder)\n",
    "        self.k = k\n",
    "        self.m = m\n",
    "\n",
    "    def forward(self, state):\n",
    "        q_z = self.encoder(state)\n",
    "\n",
    "        # Draw k samples\n",
    "        z_samples = [q_z.rsample() for _ in range(self.k)]\n",
    "        reconstructions = [self.decoder(z) for z in z_samples]\n",
    "\n",
    "        return reconstructions, q_z, z_samples\n",
    "\n",
    "    def loss(self, state, reconstructions, q_z, z_samples):\n",
    "        log_pxs = [D.Normal.log_prob(recon, state).sum(1) for recon in reconstructions]\n",
    "        log_pzs = [D.Normal(0, 1).log_prob(z).sum(1) for z in z_samples]\n",
    "        log_qzs = [q_z.log_prob(z).sum(1) for z in z_samples]\n",
    "\n",
    "\n",
    "        weights = [log_px + log_pz - log_qz for log_px, log_pz, log_qz in zip(log_pxs, log_pzs, log_qzs)]\n",
    "        log_sum = torch.logsumexp(torch.stack(weights), dim=0) - torch.log(torch.tensor(float(k)))\n",
    "        loss = - log_sum.mean(0)\n",
    "        return loss\n",
    "\n",
    "    def NLL(self, state):\n",
    "        # q_z = self.encoder(state)\n",
    "        # Draw m samples\n",
    "        z_samples = [torch.randn_like(q_z.mean) for _ in range(self.m)]\n",
    "        reconstructions = [self.decoder(z) for z in z_samples]\n",
    "        log_pxs = [D.Normal.log_prob(recon, state).sum(1) for recon in reconstructions]\n",
    "        log_pzs = [D.Normal(0, 1).log_prob(z).sum(1) for z in z_samples]\n",
    "        # Naive Monte Carlo for estimating the log likelihood\n",
    "        NLL_temp = torch.stack([log_px + log_pz for log_px, log_pz in zip(log_pxs, log_pzs)])\n",
    "        NLL = torch.logsumexp(NLL_temp, dim=0) - torch.log(torch.tensor(float(self.m)))\n",
    "        return NLL.mean(0)\n",
    "\n",
    "to_pil_image = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = torchvision.datasets.MNIST('./', download=True, transform=transform)\n",
    "\n",
    "input_dim = 28 * 28\n",
    "batch_size = 300\n",
    "num_epochs = 2\n",
    "learning_rate = 0.001\n",
    "hidden_size = 512\n",
    "latent_size = 16\n",
    "latent_size_list = [2,8,32,128]\n",
    "# IWAE\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    mnist, batch_size=64,\n",
    "    shuffle=True, \n",
    "    pin_memory=torch.cuda.is_available())\n",
    "\n",
    "sample,_= next(iter(dataloader))\n",
    "\n",
    "plt.figure()\n",
    "for i in range(64):\n",
    "    plt.subplot(8, 8, i+1)\n",
    "    plt.imshow(sample[i][0], cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.savefig('sample')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    mnist, batch_size=batch_size,\n",
    "    shuffle=True, \n",
    "    pin_memory=torch.cuda.is_available())\n",
    "\n",
    "print('Number of samples: ', len(mnist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [[],[],[],[]] # to store KL loss after each epoch\n",
    "losses_r = [[],[],[],[]] # to store reconstruction loss after each epoch\n",
    "images = [[],[],[],[]] # to store images generatd by the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.view(-1,input_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0 10 751.6187744140625 -753.6168823242188\n",
      "2 0 20 751.11474609375 -752.541015625\n",
      "2 0 30 747.8497924804688 -749.5022583007812\n",
      "2 0 40 746.6685180664062 -748.5628051757812\n",
      "2 0 50 746.1548461914062 -747.9866333007812\n",
      "2 0 60 746.1951904296875 -748.044189453125\n",
      "2 0 70 744.6294555664062 -746.66259765625\n",
      "2 0 80 745.0967407226562 -747.22216796875\n",
      "2 0 90 744.1720581054688 -746.2561645507812\n",
      "2 0 100 744.6077880859375 -746.7761840820312\n",
      "2 0 110 743.651123046875 -745.8710327148438\n",
      "2 0 120 743.6025390625 -745.9633178710938\n",
      "2 0 130 743.4608764648438 -745.8451538085938\n",
      "2 0 140 742.9369506835938 -745.2643432617188\n",
      "2 0 150 742.6515502929688 -745.0513305664062\n",
      "2 0 160 743.854248046875 -746.2384033203125\n",
      "2 0 170 742.3068237304688 -744.7643432617188\n",
      "2 0 180 742.8029174804688 -745.2426147460938\n",
      "2 0 190 743.0025024414062 -745.4129028320312\n",
      "2 1 0 742.8382568359375 -745.3704223632812\n",
      "2 1 10 742.9073486328125 -745.4072265625\n",
      "2 1 20 743.048095703125 -745.5760498046875\n",
      "2 1 30 742.5347290039062 -744.9735717773438\n",
      "2 1 40 742.87060546875 -745.3826904296875\n",
      "2 1 50 742.5744018554688 -745.0347290039062\n",
      "2 1 60 742.1522827148438 -744.5397338867188\n",
      "2 1 70 742.6608276367188 -745.1394653320312\n",
      "2 1 80 741.31298828125 -743.9066162109375\n",
      "2 1 90 742.0066528320312 -744.450439453125\n",
      "2 1 100 742.1656494140625 -744.72021484375\n",
      "2 1 110 742.693359375 -745.3023681640625\n",
      "2 1 120 741.6304931640625 -744.2293701171875\n",
      "2 1 130 742.9164428710938 -745.3342895507812\n",
      "2 1 140 741.4236450195312 -743.9959106445312\n",
      "2 1 150 742.41650390625 -744.8668823242188\n",
      "2 1 160 741.7576293945312 -744.2720336914062\n",
      "2 1 170 742.6084594726562 -745.012451171875\n",
      "2 1 180 741.723388671875 -744.2791137695312\n",
      "2 1 190 741.9661254882812 -744.4660034179688\n",
      "8 0 0 825.9131469726562 -809.4859008789062\n",
      "8 0 10 752.7196044921875 -759.973876953125\n",
      "8 0 20 751.9547119140625 -759.9149780273438\n",
      "8 0 30 749.9564208984375 -757.9841918945312\n",
      "8 0 40 748.4248657226562 -756.6895141601562\n",
      "8 0 50 747.82763671875 -755.9862060546875\n",
      "8 0 60 746.399169921875 -755.2703857421875\n",
      "8 0 70 745.6868896484375 -755.0493774414062\n",
      "8 0 80 745.0889282226562 -754.5670776367188\n",
      "8 0 90 744.9759521484375 -754.9906005859375\n",
      "8 0 100 744.2940063476562 -754.4398803710938\n",
      "8 0 110 743.6187744140625 -753.8756713867188\n",
      "8 0 120 743.5953369140625 -753.8643188476562\n",
      "8 0 130 742.859130859375 -753.258544921875\n",
      "8 0 140 743.053955078125 -753.493896484375\n",
      "8 0 150 742.451416015625 -753.0108032226562\n",
      "8 0 160 741.7402954101562 -752.2149658203125\n",
      "8 0 170 742.687744140625 -753.146728515625\n",
      "8 0 180 742.1337280273438 -752.434814453125\n",
      "8 0 190 741.85302734375 -752.1633911132812\n",
      "8 1 0 741.8820190429688 -752.2219848632812\n",
      "8 1 10 742.2532348632812 -752.6854858398438\n",
      "8 1 20 741.8931274414062 -752.3177490234375\n",
      "8 1 30 741.9545288085938 -752.3856201171875\n",
      "8 1 40 741.7599487304688 -752.115966796875\n",
      "8 1 50 740.8966064453125 -751.4147338867188\n",
      "8 1 60 741.4058837890625 -751.8827514648438\n",
      "8 1 70 740.8660888671875 -751.1970825195312\n",
      "8 1 80 741.4988403320312 -751.886962890625\n",
      "8 1 90 741.2606201171875 -751.7720336914062\n",
      "8 1 100 741.8646240234375 -752.442626953125\n",
      "8 1 110 741.2949829101562 -751.7284545898438\n",
      "8 1 120 740.8021850585938 -751.2234497070312\n",
      "8 1 130 741.0983276367188 -751.8023681640625\n",
      "8 1 140 740.652099609375 -751.3140258789062\n",
      "8 1 150 740.7417602539062 -751.2643432617188\n",
      "8 1 160 741.1128540039062 -751.5252685546875\n",
      "8 1 170 741.1787719726562 -751.6814575195312\n",
      "8 1 180 740.8943481445312 -751.387939453125\n",
      "8 1 190 740.5812377929688 -751.2185668945312\n",
      "32 0 0 827.8790893554688 -840.0960693359375\n",
      "32 0 10 754.1448364257812 -790.7105712890625\n",
      "32 0 20 752.834716796875 -789.9614868164062\n",
      "32 0 30 751.6461181640625 -789.9222412109375\n",
      "32 0 40 749.601806640625 -788.6298217773438\n",
      "32 0 50 749.0992431640625 -788.9560546875\n",
      "32 0 60 747.0557250976562 -787.4407348632812\n",
      "32 0 70 747.2538452148438 -788.1781005859375\n",
      "32 0 80 747.1807250976562 -788.4369506835938\n",
      "32 0 90 745.7700805664062 -787.3695678710938\n",
      "32 0 100 745.657470703125 -787.4442138671875\n",
      "32 0 110 744.9136962890625 -786.920654296875\n",
      "32 0 120 745.2743530273438 -787.1627197265625\n",
      "32 0 130 744.052001953125 -786.1336669921875\n",
      "32 0 140 744.7259521484375 -786.7418823242188\n",
      "32 0 150 744.1561279296875 -786.3154296875\n",
      "32 0 160 744.536865234375 -786.4248657226562\n",
      "32 0 170 744.6532592773438 -786.5223999023438\n",
      "32 0 180 744.0188598632812 -786.2737426757812\n",
      "32 0 190 744.1259155273438 -786.1588745117188\n",
      "32 1 0 743.7222290039062 -785.7338256835938\n",
      "32 1 10 743.9625244140625 -786.0611572265625\n",
      "32 1 20 743.08935546875 -785.3071899414062\n",
      "32 1 30 743.6456298828125 -785.608642578125\n",
      "32 1 40 743.4137573242188 -785.274658203125\n",
      "32 1 50 743.4508056640625 -785.490966796875\n",
      "32 1 60 743.647216796875 -785.6468505859375\n",
      "32 1 70 743.1649780273438 -785.0601806640625\n",
      "32 1 80 742.3216552734375 -784.3792114257812\n",
      "32 1 90 742.6130981445312 -784.7741088867188\n",
      "32 1 100 742.468017578125 -784.3347778320312\n",
      "32 1 110 742.8591918945312 -784.827392578125\n",
      "32 1 120 742.1083984375 -783.9221801757812\n",
      "32 1 130 743.291259765625 -784.9581298828125\n",
      "32 1 140 742.832275390625 -784.5458374023438\n",
      "32 1 150 742.3675537109375 -784.0790405273438\n",
      "32 1 160 742.3901977539062 -783.9547119140625\n",
      "32 1 170 742.5974731445312 -784.232666015625\n",
      "32 1 180 742.5692749023438 -784.1890869140625\n",
      "32 1 190 742.040283203125 -783.4532470703125\n",
      "128 0 0 827.5051879882812 -963.8526000976562\n",
      "128 0 10 756.9840087890625 -918.2410278320312\n",
      "128 0 20 753.1651611328125 -916.755859375\n",
      "128 0 30 751.86669921875 -915.9861450195312\n",
      "128 0 40 750.30517578125 -915.04541015625\n",
      "128 0 50 749.798828125 -914.686279296875\n",
      "128 0 60 747.871826171875 -913.3468627929688\n",
      "128 0 70 748.2578125 -914.1765747070312\n",
      "128 0 80 747.4923706054688 -914.3158569335938\n",
      "128 0 90 746.481689453125 -913.3882446289062\n",
      "128 0 100 746.5142822265625 -913.673095703125\n",
      "128 0 110 746.5147094726562 -913.7118530273438\n",
      "128 0 120 746.0463256835938 -913.2095947265625\n",
      "128 0 130 745.353515625 -912.7125244140625\n",
      "128 0 140 745.7651977539062 -913.013671875\n",
      "128 0 150 745.9193115234375 -913.5760498046875\n",
      "128 0 160 745.0474243164062 -912.897216796875\n",
      "128 0 170 744.799560546875 -912.7814331054688\n",
      "128 0 180 744.633544921875 -912.4039306640625\n",
      "128 0 190 744.9415893554688 -912.76708984375\n",
      "128 1 0 744.4620971679688 -912.6212768554688\n",
      "128 1 10 743.9375 -911.970703125\n",
      "128 1 20 744.337890625 -912.6282348632812\n",
      "128 1 30 743.8804931640625 -912.1372680664062\n",
      "128 1 40 744.0536499023438 -912.31103515625\n",
      "128 1 50 743.8778076171875 -912.2070922851562\n",
      "128 1 60 744.2366943359375 -912.2090454101562\n",
      "128 1 70 743.6571655273438 -912.056884765625\n",
      "128 1 80 744.013916015625 -912.270751953125\n",
      "128 1 90 743.7072143554688 -912.1443481445312\n",
      "128 1 100 743.8226318359375 -912.1923217773438\n",
      "128 1 110 743.6583251953125 -912.0651245117188\n",
      "128 1 120 743.314697265625 -911.6468505859375\n",
      "128 1 130 743.4693603515625 -911.9755249023438\n",
      "128 1 140 743.2938842773438 -911.3648681640625\n",
      "128 1 150 742.9532470703125 -911.2684326171875\n",
      "128 1 160 743.2476806640625 -911.5938720703125\n",
      "128 1 170 742.884765625 -911.487060546875\n",
      "128 1 180 743.5540161132812 -911.958740234375\n",
      "128 1 190 742.75439453125 -911.281982421875\n"
     ]
    }
   ],
   "source": [
    "for index,latent_size in enumerate(latent_size_list):\n",
    "    encoder = Encoder(input_dim, hidden_size, latent_size)\n",
    "    decoder = Decoder(latent_size, hidden_size, input_dim)\n",
    "    iwae = IWAE(encoder, decoder, k, 1000).to(device)\n",
    "    optimizer = optim.Adam(iwae.parameters(), lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        i=0\n",
    "        for data in dataloader:\n",
    "            inputs, _ = data\n",
    "            inputs = inputs.view(-1, input_dim).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            reconstructions, q_z, z_samples = iwae(inputs)\n",
    "            loss = iwae.loss(inputs, reconstructions, q_z, z_samples)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            l = loss.item()\n",
    "            losses[index].append(l)\n",
    "            if(i%10 == 0):\n",
    "                sample_d,_,_ = iwae(sample)\n",
    "                sample_image = sample_d[0].loc.view(-1,1,28,28)\n",
    "                generated_img = make_grid(sample_image)\n",
    "                save_generator_image(generated_img, f\"./output-{latent_size}/latent{latent_size}_sample_round{i + 190*epoch}.png\")\n",
    "                images[index].append(generated_img)\n",
    "                NLL = iwae.NLL(inputs)\n",
    "                print(latent_size, epoch, i, l, NLL.item())\n",
    "            i+=1\n",
    "        torch.save(iwae.state_dict(), f'./output-{latent_size}/iwae{latent_size}.pth')\n",
    "        imgs = [np.array(to_pil_image(img)) for img in images[index]]\n",
    "        imageio.mimsave(f'./output-{latent_size}/{latent_size}-latent-sample_images.gif', imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure()\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i,loss \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[43mlosses\u001B[49m):\n\u001B[1;32m      3\u001B[0m     plt\u001B[38;5;241m.\u001B[39mplot(loss, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlatent dimension \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlatent_size_list[i]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m-KL loss\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39msavefig(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./loss.png\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'losses' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for index,latent_size in enumerate(latent_size_list):\n",
    "    encoder = Encoder(input_dim, hidden_size, latent_size)\n",
    "    decoder = Decoder(latent_size, hidden_size, input_dim)\n",
    "    iwae = IWAE(encoder, decoder, 5, 100).to(device)\n",
    "    optimizer = optim.Adam(iwae.parameters(), lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        i=0\n",
    "        for data in dataloader:\n",
    "            inputs, _ = data\n",
    "            inputs = inputs.view(-1, input_dim).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            p_x, q_z, z_samples = iwae(inputs)\n",
    "            log_weights_lst = []\n",
    "            # Compute log weights\n",
    "            for j in range(k):\n",
    "                log_likelihoods = p_x[j].log_prob(inputs).sum(-1)\n",
    "                log_weights = log_likelihoods - kls\n",
    "                log_weights_lst.append(log_weights)\n",
    "            # Use the log-sum-exp trick\n",
    "            log_sum = torch.logsumexp(torch.stack(log_weights_lst), dim=0) - torch.log(torch.tensor(float(k)))\n",
    "            loss = - log_sum.mean(0)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            l = loss.item()\n",
    "            losses[index].append(l)\n",
    "            if(i%10 == 0):\n",
    "                sample_d,_= iwae(sample)\n",
    "                sample_image = sample_d[0].loc.view(-1,1,28,28)\n",
    "                generated_img = make_grid(sample_image)\n",
    "                save_generator_image(generated_img, f\"./output-{latent_size}/latent{latent_size}_sample_round{i + 190*epoch}.png\")\n",
    "                images[index].append(generated_img)\n",
    "                print(latent_size, epoch, i, l)\n",
    "            i+=1\n",
    "        torch.save(iwae.state_dict(), f'./output-{latent_size}/iwae{latent_size}.pth')\n",
    "        imgs = [np.array(to_pil_image(img)) for img in images[index]]\n",
    "        imageio.mimsave(f'./output-{latent_size}/{latent_size}-latent-sample_images.gif', imgs)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T22:48:41.121401Z",
     "start_time": "2023-10-09T22:48:41.030118Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i,loss in enumerate(losses):\n",
    "    plt.plot(loss, label=f'latent dimension {latent_size_list[i]}-KL loss')\n",
    "plt.savefig('./loss.png')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "print(len(losses_r))\n",
    "for i,loss_r in enumerate(losses_r):   \n",
    "    plt.plot(loss_r, label=f'latent dimension {latent_size_list[i]}-reconstruct likelihood')\n",
    "    plt.legend()\n",
    "plt.savefig('./loss_r.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
